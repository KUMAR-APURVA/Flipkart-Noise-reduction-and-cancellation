{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code works only on wav file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function flags2segs() finds the segments of the audio on the basis of different speakers and it gives a key value(flag) to each speaker. It returns the segments and flags corresponding to each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flags2segs(Flags, window):\n",
    "    '''\n",
    "    ARGUMENTS:\n",
    "     - Flags:     a sequence of class flags (per time window)\n",
    "     - window:    window duration (in seconds)\n",
    "\n",
    "    RETURNS:\n",
    "     - segs:    a sequence of segment's limits: segs[i,0] is start and segs[i,1] are start and end point of segment i\n",
    "     - classes:    a sequence of class flags: class[i] is the class ID of the i-th segment\n",
    "    '''\n",
    "\n",
    "    preFlag = 0\n",
    "    curFlag = 0\n",
    "    numOfSegments = 0\n",
    "\n",
    "    curVal = Flags[curFlag]\n",
    "    segsList = []\n",
    "    classes = []\n",
    "    while (curFlag < len(Flags) - 1):\n",
    "        stop = 0\n",
    "        preFlag = curFlag\n",
    "        preVal = curVal\n",
    "        while (stop == 0):\n",
    "            curFlag = curFlag + 1\n",
    "            tempVal = Flags[curFlag]\n",
    "            if ((tempVal != curVal) | (curFlag == len(Flags) - 1)):  # stop\n",
    "                numOfSegments = numOfSegments + 1\n",
    "                stop = 1\n",
    "                curSegment = curVal\n",
    "                curVal = Flags[curFlag]\n",
    "                segsList.append((curFlag * window))\n",
    "                classes.append(preVal)\n",
    "    segs = numpy.zeros((len(segsList), 2))\n",
    "\n",
    "    for i in range(len(segsList)):\n",
    "        if i > 0:\n",
    "            segs[i, 0] = segsList[i-1]\n",
    "        segs[i, 1] = segsList[i]\n",
    "    return (segs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Desktop/Audio Recordings/new_1(1).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  3\n",
      "{\"app_session_id\":\"33e0d858-3d6c-46f1-b41e-6dacd8360af9\",\"transcriptions\":[{\"utf_text\":\"सोनी\",\"utf_text_en\":\"sony\",\"confidence_per_word\":[],\"confidence_score\":0.704957},{\"utf_text\":\"शो मी\",\"utf_text_en\":\"show me\",\"confidence_per_word\":[],\"confidence_score\":0.54414}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n",
      "/Users/macbook/Desktop/Audio Recordings/new_1(2).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 4 - 1) = 3 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  2\n",
      "{\"app_session_id\":\"1ec78481-e380-4cc5-8e2e-23d7072a044d\",\"transcriptions\":[{\"utf_text\":\"\",\"utf_text_en\":\"\",\"confidence_per_word\":[],\"confidence_score\":0.874107},{\"utf_text\":\" \",\"utf_text_en\":\"\",\"confidence_per_word\":[],\"confidence_score\":0.0}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n",
      "/Users/macbook/Desktop/Audio Recordings/new_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 3 - 1) = 2 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  3\n",
      "{\"app_session_id\":\"47211f33-616c-423f-a17a-c71aa3ed951a\",\"transcriptions\":[{\"utf_text\":\"मुझे मोबाइल लेना है\",\"utf_text_en\":\"mujhe mobile lena hai\",\"confidence_per_word\":[],\"confidence_score\":0.746328},{\"utf_text\":\"मुझे मोबाइल देना है\",\"utf_text_en\":\"mujhe mobile daina hai\",\"confidence_per_word\":[],\"confidence_score\":0.727263}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n",
      "/Users/macbook/Desktop/Audio Recordings/new_10(1).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 3 - 1) = 2 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  6\n",
      "{\"app_session_id\":\"b7809819-9581-41ee-aff7-0be92b5ef44e\",\"transcriptions\":[{\"utf_text\":\"सर दे दो जो\",\"utf_text_en\":\"sir de do jo\",\"confidence_per_word\":[],\"confidence_score\":0.536236},{\"utf_text\":\"सर दे दो एक जो\",\"utf_text_en\":\"sir de do ek jo\",\"confidence_per_word\":[],\"confidence_score\":0.532201}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n",
      "/Users/macbook/Desktop/Audio Recordings/new_10(2).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 3 - 1) = 2 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  4\n",
      "{\"app_session_id\":\"6e269439-eb8c-4e71-9145-81138799fd8f\",\"transcriptions\":[{\"utf_text\":\"\",\"utf_text_en\":\"\",\"confidence_per_word\":[],\"confidence_score\":0.874107},{\"utf_text\":\" \",\"utf_text_en\":\"\",\"confidence_per_word\":[],\"confidence_score\":0.0}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n",
      "/Users/macbook/Desktop/Audio Recordings/new_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 3 - 1) = 2 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  4\n",
      "{\"app_session_id\":\"5c3b86cf-971e-44cb-8d92-41ec1c938a7e\",\"transcriptions\":[{\"utf_text\":\"हम लेना है\",\"utf_text_en\":\"hum lena hai\",\"confidence_per_word\":[],\"confidence_score\":0.671265},{\"utf_text\":\"होम लेना है\",\"utf_text_en\":\"home lena hai\",\"confidence_per_word\":[],\"confidence_score\":0.621145}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n",
      "/Users/macbook/Desktop/Audio Recordings/new_11(1).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 3 - 1) = 2 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  2\n",
      "{\"app_session_id\":\"8ee3384b-37c0-4afc-b7e9-1ce94555b0df\",\"transcriptions\":[{\"utf_text\":\"आपके पास रबर हैंड क्लोज है क्या\",\"utf_text_en\":\"aapke paas rubber hand close hai kya\",\"confidence_per_word\":[],\"confidence_score\":0.699902},{\"utf_text\":\"आपके पास रबर हैंड क्लोज हैं क्या\",\"utf_text_en\":\"aapke paas rubber hand close hain kya\",\"confidence_per_word\":[],\"confidence_score\":0.694825}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n",
      "/Users/macbook/Desktop/Audio Recordings/new_11(2).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 3 - 1) = 2 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  5\n",
      "{\"app_session_id\":\"381925e4-e5ee-430c-b10e-4d09f08804b9\",\"transcriptions\":[{\"utf_text\":\"स्वीका परीक्षा\",\"utf_text_en\":\"svika pariksha\",\"confidence_per_word\":[],\"confidence_score\":0.602762},{\"utf_text\":\"हस्वीका परीक्षा\",\"utf_text_en\":\"hasvika pariksha\",\"confidence_per_word\":[],\"confidence_score\":0.597349}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n",
      "/Users/macbook/Desktop/Audio Recordings/new_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  2\n",
      "{\"app_session_id\":\"8aff210b-c4a3-45ca-af73-c4dbee18f303\",\"transcriptions\":[{\"utf_text\":\"\",\"utf_text_en\":\"\",\"confidence_per_word\":[],\"confidence_score\":0.763731},{\"utf_text\":\"तो\",\"utf_text_en\":\"to\",\"confidence_per_word\":[],\"confidence_score\":0.126525}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n",
      "/Users/macbook/Desktop/Audio Recordings/new_12(1).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 3 - 1) = 2 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/macbook/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people detected in the audio are:  4\n",
      "{\"app_session_id\":\"0abb027c-d1f3-48c9-bd29-026f30ce67da\",\"transcriptions\":[{\"utf_text\":\"डी लिंक वायरलेस र\",\"utf_text_en\":\"d link wireless r\",\"confidence_per_word\":[],\"confidence_score\":0.709305},{\"utf_text\":\"डी लिंक वायरलेस रा\",\"utf_text_en\":\"d link wireless ra\",\"confidence_per_word\":[],\"confidence_score\":0.667327}],\"recording_index\":1,\"is_last\":true}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "counter = 0\n",
    "directory = '/Users/macbook/Desktop/Audio Recordings'\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    # You can remove the counter if you want to iterate over whole data.\n",
    "    if counter==10:\n",
    "        break\n",
    "    \n",
    "    if filename.endswith(\".wav\"):\n",
    "        counter+=1\n",
    "        \n",
    "        #print(os.path.join(directory, filename))\n",
    "        main_filename = filename\n",
    "        filename=os.path.join(directory, filename)\n",
    "        print(filename)\n",
    "        \n",
    "        # Here we are importing the wav file\n",
    "        import scipy.io.wavfile as wav\n",
    "        sampling_rate,sig = wav.read(filename)\n",
    "        \n",
    "        # Here we are calculating the length of signal\n",
    "        len_of_signal = len(sig)\n",
    "        \n",
    "        '''\n",
    "        Logmmse:-\n",
    "        Log-spectrum based minimum mean square error is described by Emphraim and Malah after simple MMSE.\n",
    "        This algorithm assumes a gaussian model for the complex spectral amplitude of both speech and noise.\n",
    "        It gives the optimum estimate of the log spectrum of the clean speech signal. A decision-directed\n",
    "        approach is used for estimating the a priori SNR.\n",
    "        \n",
    "        It reduces the background noise of the audio.\n",
    "        '''\n",
    "        from logmmse import logmmse_from_file\n",
    "        sig = logmmse_from_file(filename)\n",
    "        \n",
    "        \n",
    "        '''Wav file can be of 1D and 2D shape. Hence, we are converting all the wav files into 1D for easily\n",
    "        working on it.'''\n",
    "        flag = 0\n",
    "        try:\n",
    "            flag=sig.shape[1]\n",
    "        except Exception as e:\n",
    "            flag=1\n",
    "            \n",
    "        if flag==2:\n",
    "            new_sig = []\n",
    "            for i in range(len(sig)):\n",
    "                new_sig.append(sig[i][0])\n",
    "            sig = new_sig.copy()\n",
    "        \n",
    "        \n",
    "        '''For applying speaker diarization on the audio file, the file needs to have a lot of features in it\n",
    "        in order to retreive them. But sometimes size of file is small and features are not been able to \n",
    "        recognized. Hence, we are duplicating it four folds.'''\n",
    "        temp = []\n",
    "        \n",
    "        for elem in sig:\n",
    "            temp.append(elem)\n",
    "        for elem in sig:\n",
    "            temp.append(elem)\n",
    "        for elem in sig:\n",
    "            temp.append(elem)\n",
    "        for elem in sig:\n",
    "            temp.append(elem)\n",
    "            \n",
    "        sig = numpy.array(temp)\n",
    "        \n",
    "        '''Here we are calculating speaker diarization.'''\n",
    "        import pyAudioAnalysis.audioSegmentation as aS\n",
    "        cls = aS.speaker_diarization(rate=sampling_rate,sig=sig,n_speakers=0)\n",
    "        segs,flags = flags2segs(cls,0.2)\n",
    "        \n",
    "        #########PROBLEM 1##########\n",
    "        print('Number of people detected in the audio are: ',len(set(flags)))\n",
    "        \n",
    "        '''We created our own product list from where we are matching the words of speakers respectively.'''\n",
    "        import json\n",
    "        with open('product_list.json', 'r') as fp:\n",
    "            product_list = json.load(fp)\n",
    "        \n",
    "        '''Matching is taking place here.'''\n",
    "        result = {}\n",
    "        import speech_recognition as sr\n",
    "        file = filename\n",
    "  \n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "        for i in range(len(segs)):\n",
    "\n",
    "            with sr.AudioFile(file) as source:\n",
    "                audio = r.record(source,duration=(segs[i][1]-segs[i][0]),offset=segs[i][0])\n",
    "                try:\n",
    "                    text = r.recognize_google(audio)\n",
    "                except Exception as e:\n",
    "                    text = \"\"\n",
    "                text = text.split()\n",
    "                for elem in text:\n",
    "                    if elem.lower() in product_list:\n",
    "                        result[flags[i]] = 1 + result.get(flags[i],0)\n",
    "                        \n",
    "        '''result variable contains the speakers and the number of matches respectively.'''\n",
    "        #print(result)   \n",
    "        \n",
    "        '''calculating the max matched value'''\n",
    "        max_match_value=0\n",
    "        if len(result)!=0:\n",
    "            max_match_value = max(result.values())\n",
    "        \n",
    "        '''matched_flag variable will contain the flag number of speakers with max value matched.'''\n",
    "        matched_flag = []\n",
    "        for elem in result:\n",
    "            if result[elem]==max_match_value:\n",
    "                matched_flag.append(elem)\n",
    "                \n",
    "        #This will happen because our dataset is not large enough.\n",
    "        if len(matched_flag)==0:\n",
    "            segments=[]\n",
    "        \n",
    "        #If matched_flag length is 1, then we got our primary speaker.\n",
    "        elif len(matched_flag)==1:\n",
    "            segments = []\n",
    "            for i in range(len(flags)):\n",
    "                if flags[i]==matched_flag[0]:\n",
    "                    segments.append(segs[i])\n",
    "        \n",
    "        #If not, check for the maximum amplitude speaker.\n",
    "        else:\n",
    "            \n",
    "            rate = sampling_rate\n",
    "            amplitude = []\n",
    "            for flag in matched_flag:\n",
    "                for i in range(len(flags)):\n",
    "                    if flags[i]==flag:\n",
    "                        s = 0\n",
    "                        for j in range(int(segs[i][0]*rate),int(segs[i][1]*rate)):\n",
    "                            s+=abs(sig[j])\n",
    "                        amplitude.append((s/(rate*(segs[i][1]-segs[i][0])),flag))\n",
    "            max_ampl = max(amplitude)\n",
    "\n",
    "            segments = []\n",
    "            for i in range(len(flags)):\n",
    "                if flags[i]==max_ampl[1]:\n",
    "                    segments.append(segs[i])\n",
    "        \n",
    "        '''Now we have got the segments of primary speaker.'''\n",
    "        #print(segments)\n",
    "        \n",
    "        '''Now we are taking the values of signal to recreate the voice of primary speaker.'''\n",
    "        rate = sampling_rate\n",
    "        arr = []\n",
    "        for elem in segments:\n",
    "             if(int(elem[1]*rate)<=len_of_signal):\n",
    "                for j in range(int(elem[0]*rate),int(elem[1]*rate)):\n",
    "                    arr.append(sig[j])\n",
    "        \n",
    "        '''Case of exception when we have no results due to no match.'''\n",
    "        if len(arr)==0:\n",
    "            arr=[0 for i in range(rate)]\n",
    "        arr = numpy.array(arr)\n",
    "        \n",
    "        ########## MAIN PROBLEM ###########\n",
    "        '''Here we got our results. The file will contain the voice of primary speaker.'''\n",
    "        wav.write(main_filename,rate=rate,data=arr)\n",
    "        \n",
    "        '''Here we are using flipkart ASR API.'''\n",
    "        import requests\n",
    "        headers = {'Authorization' : 'Token 3715119fd7753d33bedbd3c2832752ee7b0a10c7'}\n",
    "        data = {'user' : '310' ,'language' : 'HI'}\n",
    "        files = {'audio_file' : open(main_filename,'rb')}\n",
    "        url = 'https://dev.liv.ai/liv_transcription_api/recordings/'\n",
    "        res = requests.post(url, headers = headers, data = data, files = files)\n",
    "        print(res.text)  \n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
